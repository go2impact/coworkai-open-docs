# Performance Metrics — Overview

This system analyses comprehensive behavioural data from hundreds of thousands of remote workers to generate two core performance metrics. Metrics are computed with proprietary algorithms that evolve as more data is collected.

---

## Metric Definitions

### Go2 Score

- **Measures**: Outcome effectiveness relative to role expectations
- **Comparisons**:
  - Your historical baseline performance
  - Aggregated patterns from workers in similar roles (minimum cohort: 1,000 workers)
  - Documented outcomes and deliverables
- **Interpretation**: Identifies whether work patterns correlate with successful outcomes, regardless of effort level or time investment. A worker with exceptional efficiency may maintain a solid Go2 Score while working fewer focused hours.

### My Engagement

- **Measures**: Focus intensity during active work periods
- **Method**: Calculates the density and quality of work-related actions during designated work time, filtering for:
  - Active problem-solving patterns
  - Sustained focus indicators
  - Context-appropriate tool usage
- **Role-adjusted**: Research roles expect different engagement patterns than transaction-processing roles.

---

## Score Interpretation

| Go2 Score | Engagement | Interpretation                                      |
|-----------|------------|------------------------------------------------------|
| High      | High       | Operating at peak performance with sustained focus  |
| High      | Low        | Achieving outcomes efficiently, potentially underutilized |
| Low       | High       | High effort with suboptimal methods or role misalignment |
| Low       | Low        | Performance concerns requiring intervention         |

---

## Data Sources

The system processes:

- Application usage patterns and sequences
- Communication patterns and response quality
- Work product characteristics
- Documented feedback and performance indicators
- Self-reported KPIs where available
- Contextual role requirements

Specific weightings and correlations are proprietary and continuously refined through machine learning.

---

## Baseline Establishment

- **New users**: 2–4 weeks for initial baseline
- **Accuracy improvement**: Continuous over 3–6 months
- **Role-specific adjustments**: Automatic as cohort data expands

---

## System Limitations

- Novel roles with fewer than 100 comparable workers show higher variance
- Scores reflect probabilistic correlations, not absolute performance
- Creative and strategic work may show irregular patterns during breakthrough periods
- The system optimizes for detected patterns, which may not capture all value creation methods

---

## Score Volatility

Weekly fluctuations of ±15% are normal due to:

- Project cycles
- Task variety
- System learning adjustments
- Cohort baseline shifts

Focus on 4-week rolling averages rather than daily scores.

---

## Improving Scores

The system provides role-specific recommendations based on pattern analysis. Use the chat interface to query:

- Specific behavioural patterns affecting scores
- Time-of-day performance variations
- Tool usage optimization opportunities
- Comparison with successful cohort patterns

---

## Privacy Note

Individual scores are visible only to the worker. Management sees aggregated team metrics only. Raw behavioural data is processed algorithmically without human review.

---

## Version

- **Current Algorithm**: v3.2.1
- **Last Calibration**: October 2025
- **Cohort Size**: 547,000+ workers
- **Role Categories**: 1,847
- **Task Type Clusters**: 12,300+ (aggregated from behaviorally similar activities)
- **Regional Data Pools**: 42 (covering >90 countries)
- **Update Frequency**: Weekly micro-calibration / Monthly model retrain

This system is under active development. Scoring algorithms are refined quarterly based on outcome correlation analysis.


